# 测试E2FGVI-lite速度
--model
e2fgvi_hq-lite
--dataset
davis
--data_root
datasets/
--timing

CUDA_VISIBLE_DEVICES=1 python evaluate.py --model e2fgvi_hq-lite --dataset davis --data_root datasets/ --timing

# 复现E2FGVI论文结果
--model
e2fgvi
--dataset
davis
--data_root
datasets/
--ckpt
release_model/E2FGVI-CVPR22.pth

CUDA_VISIBLE_DEVICES=1 python evaluate.py --model e2fgvi --dataset davis --data_root datasets/ --timing --ckpt release_model/E2FGVI-CVPR22.pth
All average forward run time: (0.073828) per frame [矩池云3090]

# 改进中间帧融合策略0.5，psnr提升0.1
--model
e2fgvi
--dataset
davis
--data_root
datasets/
--ckpt
release_model/E2FGVI-CVPR22.pth
--good_fusion

# 测试e2fgvi bs2 250k
--model
e2fgvi
--dataset
davis
--data_root
datasets/
--ckpt
release_model/e2fgvi_ablation_e2fgvi_baseline/gen_250000.pth

# 测试e2fgvi-lite bs2 250k flow init
--model
e2fgvi_hq-lite
--dataset
davis
--data_root
datasets/
--ckpt
release_model/e2fgvi_hq-lite_ablation_e2fgvi_hq-lite-flow-init/gen_250000.pth

CUDA_VISIBLE_DEVICES=1 python evaluate.py --model e2fgvi_hq-lite --dataset davis --data_root datasets/ --ckpt release_model/e2fgvi_hq-lite_ablation_e2fgvi_hq-lite-flow-init/gen_095000.pth
CUDA_VISIBLE_DEVICES=1 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN/gen_095000.pth --good_fusion --timing

# 测试lite-MFN
--model
lite-MFN
--dataset
davis
--data_root
datasets/

#####################################################
新建会话：tmux new -s SESSION-NAME
杀死会话：tmux kill-session -t 0
接入会话：tmux attach-session -t 0
退出并杀死当前会话：ctrl+d

# 远程连接tensorboard
ssh -p 29837 -NL 8008:localhost:9009 root@hz-t2.matpool.com
*9[G6]=zJJ#i0Z%Q
输入密码后会卡死，直接新开一个终端启动tb就好了

# 打开tb
退出环境：conda deactivate
cd /mnt/WORKSPACE/E2FGVI-hao/
tensorboard --logdir='release_model/' --port=9009
http://127.0.0.1:8008/
####################################################

# 训练e2fgvi-bs2-250k [已完成]
python train.py -c configs/ablation_e2fgvi_baseline.json
[250k, davis]: Finish evaluation... Average Frame PSNR/SSIM/VFID: 30.65/0.9590/0.180
All average forward run time: (0.074037) per frame [本地3090]
All average forward run time: (0.072967) per frame [矩池云3090]

# train_e2fgvi_hq-lite.json用于最终实验 bs6 3090单卡 250k 约110h

# 训练e2fgvi-lite bs2 3090单卡 back光流不对齐 250k 约42h 若bs4则需要约73h
python train.py -c configs/ablation_e2fgvi_hq-lite.json

# 训练e2fgvi-lite bs2 3090单卡 250k back光流不对齐 [tmux 0 灵活训练]
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_e2fgvi_hq-lite.json

# 训练e2fgvi-lite bs2 3090单卡 250k back光流对齐 [停止] 确实会好一些,我们自己用
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_e2fgvi_hq-lite-flow-align.json

# 训练e2fgvi-lite bs2 3090单卡 250k back光流不对齐 SpyNet预训练初始化 [已完成] 用这个当作baseline 速度也在0.04s左右
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_e2fgvi_hq-lite-flow-init.json
[95k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.35/0.9362/0.247
[140k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 27.76/0.9323/0.256
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.61/0.9379/0.230     # Baseline: 28.61
All average forward run time: (0.030172) per frame [矩池云3090]

# 训练lite-MFN bs2 3090单卡 250k back光流真对齐 maskflownetS [已完成] 约需要54.5h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN.json
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN/gen_250000.pth --good_fusion --timing
[95k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.43/0.9356/0.241
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.11/0.9443/0.214     # PSNR提升0.5
All average forward run time: (0.052142) per frame
All average forward run time: (0.050412) per frame [矩池云3090]

# 训练lite-MFN bs2 3090单卡 250k back光流真对齐 maskflownetS 拆掉后面的dcn对齐 认为光流对齐足够精准 [已完成] 约需要41.5h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-WoDCN.json
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-WoDCN\gen_250000.pth --good_fusion --timing
[140k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.62/0.9357/0.225 已经超过了250k的baseline，乐
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.06/0.9408/0.224     # PSNR提升0.44
All average forward run time: (0.069357) per frame [本地3090]
All average forward run time: (0.047785) per frame [矩池云3090]
重新测试速度
All average forward run time: (0.046712) per frame [矩池云3090]

# 训练lite-MFN bs2 3090单卡 250k back光流真对齐 maskflownetS 光流引导patch embedding [已完成] 需要58.3h
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-flow-guide.json
这里直接把local frame的光流接到了local frame的后面，forward对应forward，backward对应backward，
local frame 与光流对齐后t少了一帧，因此non_local_frame多取1帧中间帧; 另外注意代码里常常会把batch和t合并成为bt一个通道
CUDA_VISIBLE_DEVICES=1 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-flow-guide/gen_250000.pth --good_fusion --timing
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.01/0.9347/0.260     # 不如baseline，可能是由于编码行为不一致导致的
All average forward run time: (0.051672) per frame [矩池云3090]

# 测试使用 MaskFlowNetS 替换掉 SpyNet 后的E2FGVI速度（与官方测试方法一致）
All average forward run time: (0.093530) per frame [矩池云3090]

# 测试使用 MaskFlowNetS 替换掉 SpyNet 后, token fusion 0.75*0.75的E2FGVI速度（与官方测试方法一致）
All average forward run time: (0.072565) per frame [矩池云3090]

# 训练token缩减0.75*0.75的lite-MFN (E2FGVI-lite+MaskFlowNetS+token-spatial-fusion0.75x0.75) [已完成] 约需要52h
[95k 后由单卡转为双卡训练] 可能因为bs只有2所以双卡也只快了30%左右
python train.py -c configs/ablation_lite-MFN-token-fusion.json
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-token-fusion/gen_250000.pth --good_fusion --timing
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.42/0.9376/0.244     # PSNR降低0.19
All average forward run time: (0.048722) per frame [矩池云3090]

# 训练token缩减0.75*0.75的lite-MFN 共用1个token缩减和拓展模块 (E2FGVI-lite+MaskFlowNetS+token-spatial-fusion0.75x0.75) [已完成] 需要43.5h
python train.py -c configs/ablation_lite-MFN-token-fusion-simple.json
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-token-fusion-simple/gen_250000.pth --good_fusion --timing
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.48/0.9372/0.255     # PSNR降低0.13
All average forward run time: (0.071416) per frame  [本地3090]

# 训练token缩减0.75*0.75的lite-MFN 共用1个token缩减和拓展模块，加一个token的跳跃链接和fusion层 [已完成] 需要60.5h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-token-fusion-simple-skip-connect.json
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-token-fusion-simple-skip-connect/gen_250000.pth --good_fusion --timing
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.55/0.9396/0.247     # PSNR降低0.06
All average forward run time: (0.055883) per frame [矩池云3090]

# 训练token缩减0.75*0.75的lite-MFN 独立token缩减和拓展模块，渐进式token的跳跃链接和fusion层 [已完成] 约需要60h
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-token-fusion-skip-connect.json
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-token-fusion-skip-connect/gen_250000.pth --good_fusion --timing
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.14/0.9366/0.251     # PSNR降低0.47
All average forward run time: (0.054300) per frame

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长4，通道缩减4 [已完成] 约需要54h
python train.py -c configs/ablation_lite-MFN-mem.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-mem/gen_250000.pth --good_fusion --timing --memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 27.96/0.9321/0.265     # PSNR降低0.65(对比无记忆力下降1.15)

# 测试不同记忆力设置下的显存消耗以及速度
----
E2FGVI_HQ bs2 显存消耗：20.43GB
----
lite-MFN 原E2FGVI大小 bs2 显存消耗：20.97GB
----
lite-MFN 原E2FGVI大小 bs2 token fusion 不共用 75%x75% 显存消耗：20.52GB
lite-MFN 原E2FGVI大小 bs2 token fusion 不共用 跳跃链接 75%x75% 显存消耗：23.47GB
lite-MFN 原E2FGVI大小 bs2 token fusion 共用 75%x75% 显存消耗: 21.01GB
lite-MFN 原E2FGVI大小 bs2 token fusion 共用 跳跃链接 75%x75% 显存消耗: 21.01GB
----
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减1 记忆时长4 显存消耗：可以运行 [3090]
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减1 记忆时长8 显存消耗：显存溢出 [3090]
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减1 记忆时长8 拆除dcn 显存消耗：显存溢出 [3090]
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减2 记忆时长8 显存消耗：19.26GB [3090]
----
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减4 记忆时长4 显存消耗: 22.96GB 22.96GB
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减4 记忆时长8 显存消耗: 23.42GB 23.43GB
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减4 记忆时长16 显存消耗: 22.89GB 22.89GB
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减4 记忆时长32 显存消耗: 23.50GB 23.34GB
----
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减8 记忆时长4 显存消耗: 22.86GB 22.86GB
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减8 记忆时长8 显存消耗: 22.95GB 22.95GB
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减8 记忆时长16 显存消耗: 23.01GB 22.26GB
lite-MFN 原E2FGVI大小 bs2 记忆力 通道缩减8 记忆时长32 显存消耗: 22.95GB 22.90GB
----

######################################↓↓↓修改测试逻辑↓↓↓###########################################################
# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减4 [已完成] 约需要46.5h
python train.py -c configs/ablation_lite-MFN-mem-T8C4.json
CUDA_VISIBLE_DEVICES=1 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T8C4/gen_250000.pth --good_fusion --timing --memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.71                   # PSNR提升0.10(对比无记忆力下降0.40)
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.70/0.9396/0.227      # 训练时局部/非局部记忆，在测试时只输入局部帧记忆，精度变化不大
All average forward run time: (0.059241) per frame [矩池云3090]

调整至和训练一样的输入行为进行测试：局部帧的输入方式相同 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.87/0.9386/0.236
All average forward run time: (0.027871) per frame [矩池云3090]
精度相比于e2fgvi的测试逻辑提高0.16，速度快了1倍（因为每个局部帧只被计算了一次）

调整至和训练一样的输入行为进行测试：局部帧和参考帧的输入方式都相同，其中参考帧输入3帧随机不重复 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.90/0.9391/0.237
All average forward run time: (0.026051) per frame
精度相比于e2fgvi的测试逻辑提高0.19，速度更快了（因为每个局部帧只被计算了一次并且非局部帧只输入了3帧）
因为有随机的非局部帧采样所以再测一次 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.89/0.9390/0.237
All average forward run time: (0.025866) per frame
第三次测试 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.90/0.9391/0.237
All average forward run time: (0.027414) per frame
精度波动不大，速度很快

如果测试的时候记忆只存储局部帧？[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.69/0.9367/0.249
All average forward run time: (0.025671) per frame
训练和测试的逻辑不一致会导致精度的下降，另外记忆非局部帧可能也可以提升精度

测试相同测试逻辑下，e2fgvi-hq-lite的精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.18/0.9422/0.223
All average forward run time: (0.017689) per frame
坏了，相同的测试逻辑下e2fgvi-hq-lite的精度暴涨，速度也快了。。。

相同逻辑下，序列化训练的e2fgvi-hq-lite的精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.10/0.9415/0.227
All average forward run time: (0.018998) per frame
可见序列化训练确实会让精度下降，序列化的e2fgvi-hq-lite精度下降了0.08

测试相同测试逻辑下，lite-MFN的精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.25/0.9429/0.216
All average forward run time: (0.026862) per frame
相同的测试逻辑下lite-MFN的精度也提高了，速度也快了

测试相同测试逻辑下，序列化训练的lite-MFN的精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.14/0.9418/0.225
All average forward run time: (0.026544) per frame
相同的测试逻辑下，序列化训练的lite-MFN精度下降了0.11

测试相同逻辑下，官方的e2fgvi的精度 [500k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 31.73/0.9649/0.147
All average forward run time: (0.039471) per frame
相同逻辑下，官方给出的e2fgvi模型精度严重下降。。。

测试相同逻辑下，官方的e2fgvi_hq的精度 [500k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 31.75/0.9652/0.140
All average forward run time: (0.039265) per frame
相同逻辑下，官方给出的e2fgvi-hq模型精度也严重下降。。。

如果我们的记忆力模型也测试两次然后取平均值呢？[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.11/0.9411/0.224
All average forward run time: (0.055980) per frame
精度和lite-MFN加默认测试逻辑差不多了，比只推理1次精度提高了0.21
也就是说，记忆力模型刷精度可以通过相同的测试逻辑，然后推理两次实现

没有记忆力的模型也用序列推理两次的精度如何呢？[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.48/0.9450/0.214  # 目前最高的PSNR 29.48
All average forward run time: (0.051158) per frame
没有记忆力的模型用这个推理逻辑做两次平均，精度直接刷到最高29.48 。。。

使用序列化训练的lite-MFN两次序列推理取平均 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.38/0.9440/0.219
All average forward run time: (0.050378) per frame

没有记忆力的模型E2FGVI-CVPR22使用序列测试输入推理两次平均 [500k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 32.30/0.9683/0.139
All average forward run time: (0.076663) per frame
精度不如官方的测试逻辑

测试e2fgvi-bs2的baseline版本使用序列化测试的精度和速度变化 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 30.05/0.9543/0.192
All average forward run time: (0.038831) per frame

测试e2fgvi-bs2的baseline版本使用序列化测试两次平均的精度和速度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 30.42/0.9571/0.184
All average forward run time: (0.076268) per frame

测试lite-MFN压缩指数2记忆时长8的模型使用序列化测试的精度和速度变化 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.67/0.9372/0.246
All average forward run time: (0.025476) per frame
精度几乎没变 速度提升很大

测试lite-MFN压缩指数4记忆时长4的模型使用序列化测试的精度和速度变化 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.30/0.9340/0.256
All average forward run time: (0.026109) per frame
精度略微回升，速度显著提升

测试lite-MFN压缩指数8记忆时长4的模型使用序列化测试的精度和速度变化 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.39/0.9365/0.248
All average forward run time: (0.027444) per frame
精度显著回升，压缩指数越大，对于测试和训练逻辑是否一致就越敏感

测试lite-MFN压缩指数8记忆时长8的模型使用序列化测试的精度和速度变化 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.61/0.9367/0.235
All average forward run time: (0.026284) per frame

测试记忆8压缩2的lite-MFN两次序列推理精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.86/0.9393/0.231
All average forward run time: (0.054089) per frame

测试记忆4压缩4的lite-MFN两次序列推理精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.44/0.9356/0.239
All average forward run time: (0.050170) per frame

测试T4C8的lite-MFN两次序列推理精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.64/0.9390/0.228
All average forward run time: (0.050626) per frame

测试T8C8的lite-MFN两次序列推理精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.81/0.9387/0.226
All average forward run time: (0.053568) per frame

测试T8C4缓存局部帧的lite-MFN两次序列推理精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.09/0.9414/0.227
All average forward run time: (0.052377) per frame
精度不错

测试T8C4缓存局部帧，并对齐缓存的lite-MFN两次序列推理精度 [250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.15/0.9428/0.211
All average forward run time: (0.058264) per frame
对齐缓存确实把精度刷上来了。。。

######################################↑↑↑修改测试逻辑↑↑↑###########################################################


# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长4，通道缩减8 [已完成] 需要55h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T4C8.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T4C8/gen_250000.pth --good_fusion --timing --memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 27.13/0.9285/0.277      # PSNR降低1.48(对比无记忆力下降1.98)
All average forward run time: (0.060132) per frame [矩池云3090]

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减8 [已完成] 需要54.5h
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-mem-T8C8.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T8C8/gen_250000.pth --good_fusion --timing --memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.37/0.9359/0.247      # PSNR降低0.24(对比无记忆力下降0.74)
All average forward run time: (0.058200) per frame [矩池云3090]

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减2 [已完成] 需要55h
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-mem-T8C2.json
CUDA_VISIBLE_DEVICES=1 python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T8C2/gen_250000.pth --good_fusion --timing --memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.68/0.9386/0.242      # PSNR提升0.07(对比无记忆力下降0.43)
All average forward run time: (0.061538) per frame [矩池云3090]
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.51/0.9367/0.239     # 训练时混合局部帧和非局部帧，推理时【只记忆局部帧】的精度再次发生下降
All average forward run time: (0.054712) per frame [矩池云3090]
精度甚至不如记忆时长8通道缩减4的模型，看来靠暴力堆叠记忆时长和记忆通道不能一直提高精度，而且目前来说，相比于没有记忆力的模型，造成了严重的精度下降
难道是对于记忆模型的推理脚本写的有问题？ 确实有问题

# 训练e2fgvi-lite来对比序列化dataloader的训练不稳定导致的精度退化 [已完成] 需要39.11h
python train.py -c configs/ablation_e2fgvi_hq-lite-seq.json
python evaluate.py --model e2fgvi_hq-lite --dataset davis --data_root datasets/ --ckpt release_model/e2fgvi_hq-lite_ablation_e2fgvi_hq-lite-seq\gen_250000.pth --timing
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.86/0.9400/0.238     # PSNR提升0.25？？？？ 序列化训练lite-MFN会怎么样呢：答案是也不会降低精度
All average forward run time: (0.030233) per frame [本地3090Ti]

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减4，学习率降低4倍来稳定训练loss [已停止100k]
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T8C4-lr0.25.json
调低学习率并没有使得序列化训练更加稳定

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长4，通道缩减1 [未开始] 约需要h

# 训练lite-MFN来对比序列化dataloader的训练不稳定导致的精度退化or提升 [已完成] 需要44.5h
python train.py -c configs/ablation_lite-MFN-seq.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --ckpt release_model/lite-MFN_ablation_lite-MFN-seq\gen_250000.pth --good_fusion --timing
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.12/0.9432/0.226     # PSNR提升0.51 目前最高
All average forward run time: (0.070436) per frame [本地3090Ti]
序列化训练并没有影响e2fgvi-lite和lite-MFN的精度

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减4，记忆缓存只存储局部帧，防止随机的非局部帧干扰模式学习 [已完成] 需要55h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T8C4-LF.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --good_fusion --timing --memory
使用序列测试
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.90/0.9397/0.236
All average forward run time: (0.025134) per frame [矩池云3090]
不使用序列测试，使用半滑窗逻辑测试精度 with good fusion
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.61/0.9401/0.253
All average forward run time: (0.062334) per frame
不用序列测试精度下降严重，并且会明显比同时存储局部帧和非局部帧的记忆模型差

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减4，记忆缓存只存储局部帧，在增强当前帧前对齐缓存 [已完成] 需要50h
# 在压缩记忆缓存后使用光流进行token对齐，优点是可以计算缓存里每一帧与当前帧的光流并进行对齐
# 基于序列化测试精度
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T8C4-LF-align.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --good_fusion --timing --memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.91/0.9405/0.220
All average forward run time: (0.030727) per frame [本地3090]
相比于没有使用光流对齐的，且缓存了所有帧的模型，精度回升0.01，看来缓存非局部帧也是有效的？
猜测是没有缓存非局部帧导致精度下降，对齐缓存导致精度上升，一来一回抵消了
只要看看没有缓存非局部帧的模型精度表现如何就知道了
不使用序列测试，使用半滑窗逻辑测试精度 with good fusion (使用same_memory命令实现和E2FGVI尽可能一致的测试逻辑)
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 27.96/0.9367/0.226
All average forward run time: (0.058379) per frame
比不对齐缓存精度下降更严重了，对于记忆机制的订制越多，对于测试逻辑就越敏感

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减4，记忆缓存只存储局部帧，在增强当前帧前对齐缓存 [未开始] 约需要h
# 在压缩记忆缓存前使用光流进行token对齐，优点是上一帧到当前帧的光流计算更准确，缺点是不能对齐缓存里的其他已经压缩过的记忆(除非池化)，并且计算开销更大，最好只维持一次迭代的记忆缓存
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T8C4-LF-align_before.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --good_fusion --timing --memory

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减4，记忆缓存只存储局部帧，在增强当前帧前对齐缓存 [已完成] 需要51.5h
# 在压缩记忆缓存后使用光流进行token对齐，优点是可以计算缓存里每一帧与当前帧的光流并进行对齐
# 在对齐缓存时将token从通道维度上进行分组，来实现sub-token alignment，分组系数 4；目前各个通道共用1个FlowHead；没有加入额外的位置嵌入
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T8C4-LF-align-sub4.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --good_fusion --timing --memory
默认的半滑窗逻辑测试：
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.47/0.9394/0.232
All average forward run time: (0.085886) per frame [3090 Ti]
比token级别对齐精度大涨0.50！但在这个模式下精度还是比只有局部帧不对齐的差
序列测试：
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.74/0.9387/0.221
All average forward run time: (0.032889) per frame [3090 Ti]
序列测试的精度没有token级别的对齐好
序列测试x2：
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.00/0.9413/0.213
All average forward run time: (0.068087) per frame [3090 Ti]
序列测试x2的精度没有token级别的对齐好

# 训练带有记忆力机制来增强qkv的Lite-MFN train loader是序列化的，记忆力时长8，通道缩减4，记忆缓存同时存储局部帧和非局部帧，在增强当前帧前对齐缓存 [未开始] 约需要h
# 在压缩记忆缓存后使用光流进行token对齐，优点是可以计算缓存里每一帧与当前帧的光流并进行对齐
# 在对齐缓存时将token从通道维度上进行分组，来实现sub-token alignment，分组系数 4；目前各个通道共用1个FlowHead；没有加入额外的位置嵌入
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T8C4-align-sub4.json
python evaluate.py --model lite-MFN --dataset davis --data_root datasets/ --good_fusion --timing --memory

# 训练记忆时长8压缩指数4只存储局部帧的大模型large-MFN测试记忆力机制以及目前的改动对于大模型是否有效 [已完成] 需要83.5h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_large-MFN-mem-T8C4-LF.json
本地3090爆显存
如果取消对齐行为则不会爆显存
对齐操作这么吃资源？
拆掉dcn看看：拆掉dcn也会爆显存
如果只有一半的层有记忆力呢？能跑起来，但是7次以后会卡住，每次迭代非常非常慢
暂时放弃缓存对齐机制，只测试光流改动以及记忆力改动的有效性
后面想加回来可以进一步减少有记忆力的层，或者进一步压缩记忆时长和通道
flow loss用成spynet了，停掉10k，重新开启来
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model large-MFN --ckpt release_model/large-MFN_ablation_large-MFN-mem-T8C4-LF/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.99/0.9517/0.191
All average forward run time: (0.127589) per frame [本地3090]
精度不如baseline的30.65
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model large-MFN --ckpt release_model/large-MFN_ablation_large-MFN-mem-T8C4-LF/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.71/0.9485/0.210
All average forward run time: (0.045632) per frame [本地3090]
精度不如baseline
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model large-MFN --ckpt release_model/large-MFN_ablation_large-MFN-mem-T8C4-LF/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 30.01/0.9508/0.193
All average forward run time: (0.089331) per frame[本地3090]
精度不太行，可能对于大模型，也不是每一层都需要记忆力，在前面的层增加记忆力可能干扰当前帧的特征提取与信息补全

# 为了找到记忆模型精度下降的原因，训练记忆时长2只存储局部帧且不压缩的lite-MFN作为对比 [已完成] 需要55h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T2C1-LF.json
如果算力不够这个实验可以停掉，之前的实验已经证明只存储局部帧在默认推理逻辑下精度会下降
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1-LF/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.98/0.9421/0.232
All average forward run time: (0.057227) per frame [矩池云3090]
精度终于接近没有记忆力的模型了！可见长时间的记忆和当前帧差异太大，是没有好处的！另外，长时间的记忆，误差也更容易累计下来。
如果想把影响降低到最小，应该输入T1？
只存储局部帧的模型在默认的半滑窗推理逻辑中精度最高，合理，因为默认的推理逻辑输入的非局部帧数量和采样方式变化很大。只存储局部帧会更稳定
序列测试(good fusion)：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1-LF/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --good_fusion
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.84/0.9391/0.235
All average forward run time: (0.025474) per frame [矩池云3090]
为什么这个模型用序列测试精度反而不涨了呢？
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1-LF/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.85/0.9392/0.235
All average forward run time: (0.025778) per frame [矩池云3090]
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1-LF/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.02/0.9410/0.223
All average forward run time: (0.051143) per frame [矩池云3090]
精度还是不够，T2C8的模型序列推理的精度更高，应该进一步降低时序记忆时长，例如T1

# 为了找到记忆模型精度下降的原因，训练记忆时长2且不压缩的lite-MFN作为对比 [已完成] 需要55h
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-mem-T2C1.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.02/0.9354/0.240
All average forward run time: (0.055743) per frame [矩池云3090]
对比T2C1-LF，再一次坚定了我不存储非局部帧的决心
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.27/0.9347/0.232
All average forward run time: (0.025356) per frame [矩池云3090]
存储非局部帧确实没有卵用
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.44/0.9366/0.227
All average forward run time: (0.050179) per frame [矩池云3090]
对比T2C1-LF，再一次坚定了我不存储非局部帧的决心，记忆信息少的时候很明显，随机的非局部帧降低了模式学习的能力

# 记忆时长只有2，压缩指数2/4/6/8会怎么样呢？都等待探索，记忆时长和压缩指数的平衡点到底在哪里？

# 为了找到记忆模型精度下降的原因，训练记忆时长2且压缩8的lite-MFN作为对比 [已完成] 需要41h
python train.py -c configs/ablation_lite-MFN-mem-T2C8.json
默认的半滑窗逻辑测试：
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.47/0.9390/0.255
All average forward run time: (0.075989) per frame [3090Ti]
还是相比于不加精度下降
序列测试：
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.93/0.9397/0.235
All average forward run time: (0.023290) per frame [3090Ti]
序列测试x2：
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.14/0.9417/0.221
All average forward run time: (0.044951) per frame [3090Ti]
虽然记忆时长很短压缩指数也很高，但是精度表现已经超过了之前最复杂的记忆模型
综合T2C1-LF以及T2C1的模型表现来看，只存储局部帧，并且对于记忆进行进一步压缩是更好的选择，记忆时长也不宜过长，总之，应该让当前帧的结果(特征)成为主流，防止误差的累计

# 为了找到记忆模型精度下降的原因，训练记忆时长1，只存储局部帧且压缩8的lite-MFN作为对比 [已完成] 需要41.5h
python train.py -c configs/ablation_lite-MFN-mem-T1C8-LF.json
默认的半滑窗逻辑测试：
python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis] Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.41/0.9381/0.237
All average forward run time: (0.075652) per frame [3090Ti]
最短的记忆力甚至不如T2C8？？？
序列测试：
python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.75/0.9378/0.224
All average forward run time: (0.023226) per frame[3090Ti]
序列测试x2：
python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.97/0.9400/0.214
All average forward run time: (0.045340) per frame [3090Ti]
最小的扰动，最差的结果。。。

# 为了找到记忆模型精度下降的原因，训练记忆时长1，只存储局部帧且压缩8 token对齐 的lite-MFN作为对比 [已完成] 需要56h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T1C8-LF-align.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-align/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.66/0.9398/0.246
All average forward run time: (0.057382) per frame[矩池云3090]
比不对准强，但是还是很差。
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-align/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.69/0.9375/0.227
All average forward run time: (0.026004) per frame[矩池云3090]
序列测试还不如不对齐，真的无语。
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-align/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.95/0.9399/0.217
All average forward run time: (0.053937) per frame
[矩池云3090]
序列测试不如不对齐。。。

# 为了找到记忆模型精度下降的原因，训练记忆时长1，只存储局部帧且压缩8 sub-token 4 对齐 的lite-MFN作为对比 [已完成] 需要58h
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-mem-T1C8-LF-align-sub4.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-align-sub4/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.73/0.9406/0.221
All average forward run time: (0.056840) per frame [矩池云3090]
比不对齐和对齐单通道强，但是还是很差。
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-align-sub4/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.80/0.9390/0.227
All average forward run time: (0.027552) per frame [矩池云3090]
比不对齐和对齐单通道强，但是还是很差，因为信息的流动性还是不够啊！
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-align-sub4/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.97/0.9407/0.219
All average forward run time: (0.054610) per frame[矩池云3090]
比对齐单通道好一点，但是和不对齐差不多，乌鱼子。

# 为了找到记忆模型精度下降的原因，训练记忆时长1，只存储局部帧且压缩8的lite-MFN作为对比，只在最后一层记忆 [已完成] 需要44.5h
python train.py -c configs/ablation_lite-MFN-mem-T1C8-LF-LastMem.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-LastMem/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.45/0.9388/0.238
All average forward run time: (0.080145) per frame[本地3090]
比T1C8-LF强一点点，但是也很差。
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-LastMem/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.73/0.9386/0.241
All average forward run time: (0.025537) per frame[本地3090]
不咋样，说到底还是信息通路没打通。
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C8-LF-LastMem/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.00/0.9413/0.224
All average forward run time: (0.050231) per frame[本地3090]
没什么亮点，C通道线性层聚合这条路没必要再坚持走下去了，到这里就行了。后面主要探索attention

# 使用cross attention代替线性层聚合记忆力 [已完成] 大约需要41h
# 目前仅实现了对于非局部帧和局部帧都存储的缓存机制进行注意力查询，查询的是残差量，参考MixFormer
python train.py -c configs/ablation_lite-MFN-mem-T1C1-LastMem-cs.json
默认的半滑窗逻辑测试：
python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-cs/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.71/0.9397/0.234
All average forward run time: (0.075480) per frame[3090Ti]
好像没有非常好，信息已经在空间尺度流动了啊。
序列测试：
python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-cs/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.04/0.9400/0.230
All average forward run time: (0.023377) per frame[3090Ti]
信息在空间尺度流通以后，模型用很快的速度刷到了和原来推理两次/三次接近的精度！但是依然没有超过
序列测试x2：
python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-cs/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.28/0.9424/0.220
All average forward run time: (0.045485) per frame[3090Ti]
信息在空间尺度流动后，我们每帧推理1次或两次精度就可以超过之前的模型了！当然，对于记忆力的定制越多，对于测试逻辑的改变可能就越敏感。

# 实现T-cross attention [已完成] 需要56.5h
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-mem-T1C1-LastMem-csT.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.98/0.9418/0.220
All average forward run time: (0.060893) per frame[矩池云3090]
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.04/0.9405/0.234
All average forward run time: (0.026575) per frame[矩池云3090]
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.27/0.9427/0.218
All average forward run time: (0.053711) per frame[矩池云3090]
暴力把时空放到一起用纯粹的attention精度几乎没有变化，除了默认的逻辑；速度还慢了很多

# 实现T-cross attention 时间和空间注意力解耦[已完成] 需要55h
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T1C1-LastMem-csT-deco.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.36/0.9443/0.210
All average forward run time: (0.055044) per frame[矩池云3090]
绝绝子
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.12/0.9412/0.219
All average forward run time: (0.025081) per frame[矩池云3090]
我们终于得到了一个又快又好的模型
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.30/0.9429/0.212
All average forward run time: (0.049149) per frame[矩池云3090]
解耦了反而更好了！

# 实现T-N-记忆Linear聚合 [未开始]

# 测试基于 cross attention 记忆力聚合的训练显存消耗
# 基于本地3090/3090Ti测试
1.large-MFN-T1C1-LastMem-csT 可以单卡bs2正常训练 但是速度非常非常慢
2.large-MFN-T1C1-HalfMem-csT 炸裂，不可以训练

3.large-MFN-T1C1-LastMem-csT-deco 可以单卡bs2正常训练
4.large-MFN-T1C1-HalfMem-csT-deco 可以单卡bs2正常训练
5.large-MFN-T1C1-csT-deco 所有层都有记忆力，可以单卡bs2正常训练 但是速度非常非常慢 看来时空解耦进行attention非常有必要。

6.large-MFN-T2C1-LastMem-csT-deco 可以单卡bs2正常训练
7.large-MFN-T2C1-HalfMem-csT-deco 可以单卡bs2正常训练 但是速度非常非常慢

8.large-MFN-T1C1-LastMem-csT-cs 可以单卡bs2正常训练 使用cswin 不解耦也可以进行3D attention训练
9.large-MFN-T1C1-HalfMem-csT-cs 可以单卡bs2正常训练 使用cswin 不解耦也可以进行3D attention训练 甚至一半层都可以有
10.large-MFN-T1C1-csT-cs 可以单卡bs2正常训练 使用cswin 可以所有8层全开记忆力进行3D attention 牛逼

11.large-MFN-T1C1-LastMem-csT-deco-cs 当然可以 不解耦都可以
12.large-MFN-T1C1-HalfMem-csT-deco-cs 当然可以 不解耦都可以
13.large-MFN-T1C1-csT-deco-cs 当然可以 不解耦都可以 而且更快

14.large-MFN-T2C1-LastMem-csT-deco-cs-mem_att 基于矩池云3090测试 不可以单卡训练
15.large-MFN-T2C1-LastMem-csT-cs-mem_att 基于矩池云3090测试 不可以单卡训练

16.large-MFN-T1C1-LastMem-csT-tf 基于本地3090测试 可以单卡正常训练
17.large-MFN-T1C1-HalfMem-csT-tf 基于本地3090测试 可以单卡正常训练 但是速度非常非常慢
18.large-MFN-T1C1-csT-tf 基于本地3090测试 爆显存



# 实现基于窗口cross attention的记忆力聚合 [未开始]

# 实现基于temporal focal cross att的时空记忆聚合 [已完成] 需要47h   #BEST#
# 这里直接对记忆缓存的kv进行池化来完成global att的编码
python train.py -c configs/ablation_lite-MFN-mem-T1C1-LastMem-csT-tf.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-tf/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.15/0.9442/0.220
All average forward run time: (0.085500) per frame[本地3090]
focal也是有效的，但是精度提升没有解耦的时空attention有效。
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-tf/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.17/0.9428/0.222
All average forward run time: (0.027323) per frame[本地3090]
All average forward run time: (0.027848) per frame[矩池云3090]
虽然默认逻辑比不过，但是序列测试下tf会比简单解耦的att更有效！真正的又快又好~
可能是解耦的att对于输入形式的变化更加鲁棒，因为更通用，没有对于输入数据本身做一些针对性的设计。
而tf则能够在特定的输入模式下更强。
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-tf/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.44/0.9451/0.215
All average forward run time: (0.053334) per frame[本地3090]
tf推理两次直接刷到29.44，懂得都懂，很无敌

# 实现对于attention更长的记忆力聚合，在att前先用线性层聚合缓存 [已完成] 需要41.5h
# 聚合缓存自身的逻辑复用了之前的线性层设计
python train.py -c configs/ablation_lite-MFN-mem-T2C1-LastMem-csT-deco.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.81/0.9415/0.217
All average forward run time: (0.075637) per frame[3090Ti]
同样是解耦，存储时间增加一倍精度并没有提升
可能又回到了那个问题，用线性层直接融合本来就不合理，之前大量的实验证明了直接用线性层在通道上融合会很奇怪结果
现在要么是避免这个问题，把记忆时间窗口固定到1，要么是用光流等更复杂的机制去做这个对齐，但是计算开销可能得不偿失。
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.96/0.9404/0.220
All average forward run time: (0.023652) per frame[3090Ti]
记忆时间一延长，结果就开始变得奇怪起来。
和上面一样，推测是线性层聚合注意力不靠谱(通道)
而如果我用注意力先进行记忆内部的聚合，再进行cross聚合，肯定是可行的，关键就是值不值得。
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T2C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.21/0.9428/0.212
All average forward run time: (0.045693) per frame[3090Ti]
怎么说呢，推理两次精度也能上来一些，但是不如记忆一次的，属实是打扰了。

# 实现对于attention更长的记忆力聚合，在att前先用线性层聚合缓存 [已完成]
# 更长的记忆缓存会带来更好的效果吗？注意在做attention的时候通道数其实没变哦，都是聚合完的
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T4C1-LastMem-csT-deco.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T4C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.69/0.9397/0.230
All average forward run time: (0.061220) per frame[矩池云3090]
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T4C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.98/0.9404/0.225
All average forward run time: (0.027485) per frame[矩池云3090]
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T4C1-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.20/0.9427/0.212
All average forward run time: (0.054485) per frame[矩池云3090]
没什么好说的，直接用线性层聚合记忆缓存内部本身就不合理，延长记忆时间自然效果也不好

# 实现对于attention更长的记忆力聚合，在att前先用线性层聚合缓存 [已完成]
# 缓存长了，压缩比也上升会怎么样呢
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-mem-T4C4-LastMem-csT-deco.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T4C4-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.08/0.9427/0.226
All average forward run time: (0.058891) per frame[矩池云3090]
虽然线性层聚合效果不佳，但是时间拉长后压缩一下也还可以。
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T4C4-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.04/0.9411/0.225
All average forward run time: (0.027243) per frame[矩池云3090]
也还行吧，但是没有T1C1的好~
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T4C4-LastMem-csT-deco/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.30/0.9435/0.217
All average forward run time: (0.054678) per frame[矩池云3090]
和T1C1一样，你说岂不是没必要。总结下来的经验就是，不要再用线性层聚合记忆缓存了！会变得不幸

# 实现基于cs win cross att的时空记忆聚合 [已完成] 需要49h
# 该版本将T维度和空间维度合并进行3D attention，前几个epoch似乎很慢，后面突然快起来了。。。原来是因为之前的todesk没关闭
python train.py -c configs/ablation_lite-MFN-mem-T1C1-LastMem-csT-cs.json
默认的半滑窗逻辑测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-cs/gen_250000.pth --dataset davis --data_root datasets/ --good_fusion --timing --memory --same_memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.95/0.9411/0.221
All average forward run time: (0.079886) per frame[本地3090]
精度不如temp focal
序列测试：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-cs/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 28.93/0.9395/0.232
All average forward run time: (0.025941) per frame[本地3090]
效果很差，完全不是tf的对手。。。
序列测试x2：
CUDA_VISIBLE_DEVICES=0 python evaluate.py --model lite-MFN --ckpt release_model/lite-MFN_ablation_lite-MFN-mem-T1C1-LastMem-csT-cs/gen_250000.pth --dataset davis --data_root datasets/ --timing --memory --memory_double
[250k, davis]Finish evaluation... Average Frame PSNR/SSIM/VFID: 29.14/0.9416/0.217
All average forward run time: (0.050682) per frame[本地3090]
打扰了，完全不是tf的对手

# 实现基于cs win cross att的时空记忆聚合 [3090Ti] 约需要42h
# 通过解耦时间和空间进行3D attention，相当于用cs win替代deco版本里的空间attention
python train.py -c configs/ablation_lite-MFN-mem-T1C1-LastMem-csT-deco-cs.json

# 实现基于deco cs win直接对齐多个记忆张量，而不是先聚合记忆，再做cross attention(对于记忆时长大于1的情况) [tmux 0] 约需要55.5h
# mem_att 表示直接用cross attention把不同时间的记忆和当前特征聚合，而不是先用线性层聚合记忆再和当前cross att
# 相同的设置使用大模型似乎无法开启训练 也可能是矩池云的3090可用显存比较小
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_lite-MFN-mem-T2C1-LastMem-csT-deco-cs-mem_att.json

# 实现基于cs win cross att的时空记忆聚合 [tmux 1] 约需要h
# 通过解耦时间和空间进行3D attention，相当于用cs win替代deco版本里的空间attention
# 并且，仿照temporal focal的思想将各个条形窗口进行池化，获得更general的注意力
# 我称之为 temporal CSWin (csf) CSWin Focal 可以解耦也可以不解耦
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_lite-MFN-mem-T1C1-LastMem-csT-deco-csf.json

# 实现基于cs win cross att的时空记忆聚合 [未开始] 约需要h
# 通过解耦时间和空间进行3D attention，相当于用cs win替代deco版本里的空间attention
# 并且，仿照temporal focal的思想将各个条形窗口进行池化，获得更general的注意力
# 我称之为 temporal CSWin (csf) CSWin Focal 可以解耦也可以不解耦
# 优化了Focal的机制，非局部attention的滑窗沿着池化完的kv方向滑动，刚好和原来的条形kv是正交的，这样可以保证能取到全局感受野 Focal-v2
python train.py -c configs/ablation_lite-MFN-mem-T1C1-LastMem-csT-deco-csfv2.json
