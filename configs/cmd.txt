# 测试E2FGVI-lite速度
--model
e2fgvi_hq-lite
--dataset
davis
--data_root
datasets/
--timing

CUDA_VISIBLE_DEVICES=1 python evaluate.py --model e2fgvi_hq-lite --dataset davis --data_root datasets/ --timing

# 复现E2FGVI论文结果
--model
e2fgvi
--dataset
davis
--data_root
datasets/
--ckpt
release_model/E2FGVI-CVPR22.pth

# 改进中间帧融合策略0.5，psnr提升0.1
--model
e2fgvi
--dataset
davis
--data_root
datasets/
--ckpt
release_model/E2FGVI-CVPR22.pth
--good_fusion

##################################################### *9[G6]=zJJ#i0Z%Q
新建会话：tmux new -s SESSION-NAME
杀死会话：tmux kill-session -t 0
接入会话：tmux attach-session -t 0
退出并杀死当前会话：ctrl+d

# 远程连接tensorboard
ssh -p 29837 -NL 8008:localhost:6006 root@hz-t2.matpool.com
输入密码后会卡死，直接新开一个终端启动tb就好了

# 打开tb
tensorboard --logdir='release_model/' --port=6006
http://127.0.0.1:6006/
####################################################

# 训练e2fgvi-bs2-250k
python train.py -c configs/ablation_e2fgvi_baseline.json

# train_e2fgvi_hq-lite.json用于最终实验 bs6 3090单卡 250k 约110h

# 训练e2fgvi-lite bs2 3090单卡 back光流不对齐 250k 约42h 若bs4则需要约73h
python train.py -c configs/ablation_e2fgvi_hq-lite.json

# 训练e2fgvi-lite bs2 3090单卡 250k back光流不对齐 [停止]
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_e2fgvi_hq-lite.json

# 训练e2fgvi-lite bs2 3090单卡 250k back光流对齐 [停止] 确实会好一些,我们自己用
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_e2fgvi_hq-lite-flow-align.json

# 训练e2fgvi-lite bs2 3090单卡 250k back光流不对齐 SpyNet预训练初始化 [tmux 1] 用这个当作baseline 速度也在0.04s左右
CUDA_VISIBLE_DEVICES=1 python train.py -c configs/ablation_e2fgvi_hq-lite-flow-init.json

# 训练e2fgvi-lite bs2 3090单卡 250k back光流对齐 maskflownet [未开始]
CUDA_VISIBLE_DEVICES=0 python train.py -c configs/ablation_e2fgvi_hq-lite-MFN.json